{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from heapq import * \n",
    "import math\n",
    "import random\n",
    "from scipy.stats import ttest_ind\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import comb\n",
    "from apyori import apriori\n",
    "pd.options.display.max_seq_items = 1000\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrite numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cut_column(df,num):\n",
    "    for i in df.columns:\n",
    "        if df[i].nunique()>20 and  df[i].dtype != 'O':\n",
    "            df[i] = pd.qcut(df[i].values, num, retbins=True,duplicates= 'drop')[0]\n",
    "        df[i] = str(i) + ' ' + df[i].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def column_transform(df_data,df_label):\n",
    "    trans = df_data.as_matrix()\n",
    "    val = df_label.values\n",
    "    tid = {}\n",
    "    for i,j in enumerate(trans):\n",
    "        for m in j:\n",
    "            tid.setdefault(m, set()).add(i)\n",
    "    return val,tid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3 ** 2) * comb(8,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def opus_ir_pro(k,val,tid,num_col,measurement,adjust=0,pro=0,independent_pro=0):\n",
    "    k = 100\n",
    "    me_1 = np.mean(val)\n",
    "    rule = [(me_1,'empty') for i in range(k)]\n",
    "    heapify(rule)\n",
    "    current = set()\n",
    "    pro_rule = pro_a(k,me_1,rule,val,tid,num_col,current,tid.keys(),measurement,pro,adjust)\n",
    "    if independent_pro:\n",
    "        r = [i for i in pro_rule if len(i)>2]\n",
    "        d = set()\n",
    "        b = []\n",
    "        for i,j in enumerate(r):\n",
    "            for p,q in enumerate(r[:i]):\n",
    "                s1 = set(r[i][1:-1])\n",
    "                s2 = set(r[p][1:-1])\n",
    "                if s2 > s1:\n",
    "                    temp = [k for k in r[i][-1] if k not in r[p][-1]]\n",
    "                    if me_1 >= np.mean(temp):\n",
    "                        d.add(i)\n",
    "                        b.append(q)\n",
    "                    else:\n",
    "                        t , p_val = ttest_ind(val, temp, equal_var=True)\n",
    "                        if p_val > 0.05:\n",
    "                            d.add(i)\n",
    "                            b.append(q)            \n",
    "                if s1 > s2:\n",
    "                    temp = [k for k in r[p][-1] if k not in r[i][-1]]\n",
    "                    if me_1 >= np.mean(temp):\n",
    "                        d.add(p)\n",
    "                        b.append(j)\n",
    "                    else:\n",
    "                        t , p_val = ttest_ind(val, temp, equal_var=True)\n",
    "                        if p_val > 0.05:\n",
    "                            d.add(p)\n",
    "                            b.append(j)  \n",
    "        d = list(d)\n",
    "        d.sort()\n",
    "        f = []\n",
    "        for i in d[::-1]:\n",
    "            f.append(r.pop(i))\n",
    "        r_test = [i[:-1] for i in pro_rule if len(i)>2], [i[:-1] for i in r],b\n",
    "        return r_test\n",
    "    return [i[:-1] for i in pro_rule if len(i)>2]\n",
    "def pro_a(k,me_1,rule,val,tid,num_col,current,available,measurement,pro=0,adjust=0):\n",
    "    global counter\n",
    "    sofar = set()\n",
    "    for p in available:\n",
    "        new  = current.copy()\n",
    "        new.add(p)\n",
    "        if current == set():\n",
    "            upper_bound = (max([val[i] for i in tid[p]]))\n",
    "            val1 = [val[i] for i in tid[p]]\n",
    "            len_tid = 1\n",
    "            if measurement == 'mean':\n",
    "                ir = (np.mean(val1))\n",
    "            if measurement == 'impact':\n",
    "                ir = (np.mean(val1) - me_1) * len(tid[p]) \n",
    "        else:        \n",
    "            inter = set.intersection(*map(set,[tid[i] for i in new]))\n",
    "            upper_bound = (max([val[i] for i in inter]+[0]))\n",
    "            len_tid = len(new)\n",
    "            val1 = [val[i] for i in inter]\n",
    "            if measurement == 'mean':\n",
    "                ir = (np.mean(val1))\n",
    "            if measurement == 'impact':\n",
    "                ir = (np.mean(val1) - me_1) * len(val1) \n",
    "        min_heap = heappop(rule)\n",
    "        if pro:\n",
    "            if upper_bound > min_heap[0] and not math.isnan(upper_bound):\n",
    "                if ir > min_heap[0]:\n",
    "                    parent = [i for i in rule if i[1:-1] and set(i[1:-1])<new]\n",
    "                    for i in parent:\n",
    "                        if i[0] >= ir or len(val1) == 1:\n",
    "                            heappush(rule,min_heap)\n",
    "                            break\n",
    "                        t , p_val = ttest_ind(i[-1], val1, equal_var=True)\n",
    "                        if not adjust:\n",
    "                            sig = 0.05\n",
    "                        else:\n",
    "                            sig = 0.05/((2 ** len_tid) * (3 ** len_tid) * comb(num_col,len_tid))\n",
    "                        if p_val > sig:\n",
    "                            heappush(rule,min_heap)\n",
    "                            break\n",
    "                    if len(rule) == k-1:\n",
    "                        heappush(rule,tuple([ir]+list(new)+[val1]))     \n",
    "                else:\n",
    "                    heappush(rule,min_heap)\n",
    "                pro_a(k,me_1,rule,val,tid,num_col,new,sofar,measurement,pro,adjust)\n",
    "                sofar.add(p)\n",
    "            else:\n",
    "                heappush(rule,min_heap)\n",
    "        else:\n",
    "            heappush(rule,min_heap)\n",
    "            if upper_bound > min_heap[0] and not math.isnan(upper_bound):                \n",
    "                heappushpop(rule, tuple([ir]+list(new)+[val1]))\n",
    "                pro_a(k,me_1,rule,val,tid,num_col,new,sofar,measurement,pro,adjust)\n",
    "                sofar.add(p)\n",
    "    return rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Experiment result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abalone\n",
    "This data set is originally owned by Marine Resources Division. The previous usage of this data set is to predict age of abalone. In this experiment, we are going to discover the interrelationship between shucked weight and other attributes. Shuched weight is quantitative attribute and measured by grams. This dataset is sparse dataset as except qualitative attribute Sex, other attributes are quantitative attributes in 4177 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_abalone = pd.read_csv('abalone.data',header = None)\n",
    "df_abalone.columns = ['Sex','Length','Diameter','Height','Whole weight','Shucked weight','Viscera weight','Shell weigh','Rings']\n",
    "df_abalone_data = df_abalone[['Sex','Length','Diameter','Height','Whole weight','Viscera weight','Shell weigh','Rings']]\n",
    "df_abalone_label = df_abalone['Shucked weight']\n",
    "df_abalone_data = cut_column(df_abalone_data,3)\n",
    "val,tid = column_transform(df_abalone_data,df_abalone_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transactions: 24\n",
      "number of records: 4177\n",
      "100\n",
      "64\n",
      "50\n",
      "25\n",
      "21\n",
      "100\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "df_abalone = pd.read_csv('abalone.data',header = None)\n",
    "df_abalone.columns = ['Sex','Length','Diameter','Height','Whole weight','Shucked weight','Viscera weight','Shell weigh','Rings']\n",
    "df_abalone_data = df_abalone[['Sex','Length','Diameter','Height','Whole weight','Viscera weight','Shell weigh','Rings']]\n",
    "df_abalone_label = df_abalone['Shucked weight']\n",
    "df_abalone_data = cut_column(df_abalone_data,3)\n",
    "val,tid = column_transform(df_abalone_data,df_abalone_label)\n",
    "mu = opus_ir_pro(100,val,tid,8,'mean',adjust=0,pro=0,independent_pro=0)\n",
    "mu_a, mu_ai,mu_af = opus_ir_pro(100,val,tid,8,'mean',adjust=0,pro=1,independent_pro=1)\n",
    "mu_lcv, mu_lcvi,mu_lf = opus_ir_pro(100,val,tid,8,'mean',adjust=1,pro=1,independent_pro=1)\n",
    "impact = opus_ir_pro(100,val,tid,8,'impact',adjust=0,pro=0,independent_pro=0)\n",
    "impact_a, impact_ai,impact_af = opus_ir_pro(100,val,tid,8,'impact',adjust=0,pro=1,independent_pro=1)\n",
    "impact_lcv, impact_lcvi,impact_lf = opus_ir_pro(100,val,tid,8,'impact',adjust=1,pro=1,independent_pro=1)\n",
    "l = [mu,mu_a,mu_ai,mu_lcv,mu_lcvi,impact,impact_a,impact_ai,impact_lcv,impact_lcvi] \n",
    "print ('number of transactions' + ': ' + str(len(tid.keys())))\n",
    "print ('number of records' + ': ' + str(len(val)))\n",
    "for i in l:\n",
    "    print len(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with opus impact rule mining algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.17 s per loop\n"
     ]
    }
   ],
   "source": [
    "df_abalone = pd.read_csv('abalone.data',header = None)\n",
    "df_abalone.columns = ['Sex','Length','Diameter','Height','Whole weight','Shucked weight','Viscera weight','Shell weigh','Rings']\n",
    "df_abalone_data = df_abalone[['Sex','Length','Diameter','Height','Whole weight','Viscera weight','Shell weigh','Rings']]\n",
    "df_abalone_label = df_abalone['Shucked weight']\n",
    "df_abalone_data = cut_column(df_abalone_data,3)\n",
    "df_abalone_data.to_csv('df_abalone_data_weka.csv',index = False)\n",
    "val,tid = column_transform(df_abalone_data,df_abalone_label)\n",
    "%timeit (opus_ir_pro(100,val,tid,8,'mean',adjust=0,pro=0,independent_pro=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834\n",
      "1 loop, best of 3: 3.45 s per loop\n"
     ]
    }
   ],
   "source": [
    "transactions = df_abalone_data.values.tolist()\n",
    "print (len(list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))\n",
    "%timeit ((list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.66365340909090909,\n",
       "  'Rings (11.0, 29.0]',\n",
       "  'Whole weight (1.03, 2.826]',\n",
       "  'Height (0.16, 1.13]',\n",
       "  'Sex M',\n",
       "  'Diameter (0.465, 0.65]'),\n",
       " (0.66365340909090909,\n",
       "  'Sex M',\n",
       "  'Whole weight (1.03, 2.826]',\n",
       "  'Height (0.16, 1.13]',\n",
       "  'Diameter (0.465, 0.65]',\n",
       "  'Shell weigh (0.294, 1.005]',\n",
       "  'Rings (11.0, 29.0]')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in mu if i[0] == 0.66365340909090909]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:<br>\n",
    "In this experiment, we aim to find top 100 impact rules with measurement mean, when rank the target mean of all combination of itemset, 0.66365340909090909 is rank in 47, so these two rules should in the resulting rules.However, in these two rules, we discovered that the target mean of these two rules are the same, and the first rule is the parent rule of the second rule. Thus, with property of non redundancy algorithm, the second rule will be filtered.Beside the theoretical analysis of this problem, we could also use domain expertise to explain why this impact rule is not interesting.First, the only difference of these two impact rules is 'Shell weight (0.294, 1.005)', but in this experiment the target variable is shucked weight, so the second rule is redundant to the first rule by adding meaningless item. What is more, in the consideration of cost, we prefer do less measurements when the target of two rules are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Forest fire\n",
    "This data set is created by Cortez and Morais (2017), the originally target of this data set is to predict forest fire area. We will try to find interrelationship between forest fire area and other attributes. Totally 9 attributes are included in this dataset, with 2 qualitative attributes and 7 quantitative attributes in 517 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transactions: 17\n",
      "number of records: 517\n",
      "100\n",
      "15\n",
      "15\n",
      "14\n",
      "14\n",
      "100\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "def cut_column(df,num):\n",
    "    for i in df.columns:\n",
    "        if i == 'rain':\n",
    "            df.rain[df['rain'] > 0] = 1\n",
    "        elif df[i].nunique()>num and  df[i].dtype != 'O':\n",
    "            df[i] = pd.qcut(df[i].values, num, retbins=True,duplicates= 'drop')[0]\n",
    "        df[i] = str(i) + ' ' + df[i].astype(str)\n",
    "        \n",
    "    return df\n",
    "df_fire = pd.read_csv('forestfires.csv',header = 0)\n",
    "df_fire_data = df_fire[[u'X', u'Y', u'temp',u'RH', u'wind', u'rain']]\n",
    "df_fire_label = np.log(np.log(df_fire[df_fire.columns[-1]]+1)+1)\n",
    "cut_column(df_fire_data,3)\n",
    "val,tid = column_transform(df_fire_data,df_fire_label)\n",
    "mu = opus_ir_pro(100,val,tid,6,'mean',adjust=0,pro=0,independent_pro=0)\n",
    "mu_a, mu_ai,mu_af = opus_ir_pro(100,val,tid,6,'mean',adjust=0,pro=1,independent_pro=1)\n",
    "mu_lcv, mu_lcvi,mu_lf = opus_ir_pro(100,val,tid,6,'mean',adjust=1,pro=1,independent_pro=1)\n",
    "impact = opus_ir_pro(100,val,tid,6,'impact',adjust=0,pro=0,independent_pro=0)\n",
    "impact_a, impact_ai,impact_af = opus_ir_pro(100,val,tid,6,'impact',adjust=0,pro=1,independent_pro=1)\n",
    "impact_lcv, impact_lcvi,impact_lf = opus_ir_pro(100,val,tid,6,'impact',adjust=1,pro=1,independent_pro=1)\n",
    "l = [mu,mu_a,mu_ai,mu_lcv,mu_lcvi,impact,impact_a,impact_ai,impact_lcv,impact_lcvi] \n",
    "print ('number of transactions' + ': ' + str(len(tid.keys())))\n",
    "print ('number of records' + ': ' + str(len(val)))\n",
    "for i in l:\n",
    "    print len(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with opus impact rule mining algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 12.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "def cut_column(df,num):\n",
    "    for i in df.columns:\n",
    "        if df[i].nunique()>num and  df[i].dtype != 'O':\n",
    "            df[i] = pd.qcut(df[i].values, num, retbins=True,duplicates= 'drop')[0]\n",
    "        df[i] = str(i) + ' ' + df[i].astype(str)\n",
    "    return df\n",
    "df_fire = pd.read_csv('forestfires.csv',header = 0)\n",
    "df_fire_data = df_fire[[u'temp',u'RH', u'wind', u'rain']]\n",
    "df_fire_label = np.log(np.log(df_fire[df_fire.columns[-1]]+1)+1)\n",
    "cut_column(df_fire_data,3)\n",
    "df_fire_data.to_csv('df_fire_data_weka.csv',index = False)\n",
    "val,tid = column_transform(df_fire_data,df_fire_label)\n",
    "%timeit (opus_ir_pro(100,val,tid,6,'mean',adjust=0,pro=0,independent_pro=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "100 loops, best of 3: 5.12 ms per loop\n"
     ]
    }
   ],
   "source": [
    "transactions = df_fire_data.values.tolist()\n",
    "print (len(list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))\n",
    "%timeit ((list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.1195413345979819,\n",
       "  'rain 0.0',\n",
       "  'X (0.999, 3.0]',\n",
       "  'temp (21.4, 33.3]',\n",
       "  'RH (14.999, 35.0]',\n",
       "  'Y (4.0, 5.0]'),\n",
       " (1.2010577376605767,\n",
       "  'rain 0.0',\n",
       "  'temp (21.4, 33.3]',\n",
       "  'wind (0.399, 3.1]',\n",
       "  'Y (4.0, 5.0]',\n",
       "  'RH (14.999, 35.0]',\n",
       "  'X (0.999, 3.0]')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in mu if i[0] in [1.1195413345979819, 1.2010577376605767] and i[1] == 'rain 0.0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:<br>\n",
    "Target mean value 1.2010577376605767 is higher than 1.1195413345979819, but when applying t test, we found that the p value = 0.79422287525945057, with significant level set to 0.05.\n",
    "According to the statistical theory, we accept the null hypothesis, there are no significant difference between the mean value of these two samples. Thus, the second rule will not be in the resulting rule as it is not productive.Beside the statistical analysis, we could also explain why this impact rule is not interesting with domain expertise. We discover that the difference between these two rules is item 'wind (0.399, 3.1). As we apply three bin discretization for numerical attributes, the three bins for attribute wind are 'wind (0.399, 3.1)', 'wind (3.1, 4.9)', 'wind (4.9, 9.4)'. while higher wind speed conduct more area of forest fire, add item wind (0.399, 3.1) which is smallest wind speed range does not make too much sense that will conduct more area of forest fire, the rule is discovered by chance and not interesting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transactions: 303\n",
      "number of records: 201\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "imports = pd.read_csv('imports-85.data',header = -1)\n",
    "imports.columns = ['symboling','normalized-losses','make','fuel-type','aspiration','num-of-doors',\n",
    "                   'body-style','drive-wheels','engine-location','wheel-base','length','width','height',\n",
    "                   'curb-weight','engine-type','num-of-cylinders','engine-size','fuel-system','bore',\n",
    "                   'stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg','price']\n",
    "imports = imports[imports.price.apply(lambda x: x.isdigit())]\n",
    "df_imports_data = imports[['symboling','normalized-losses','make','fuel-type','aspiration','num-of-doors',\n",
    "                        'body-style','drive-wheels','engine-location','wheel-base','length','width','height',\n",
    "                        'curb-weight','engine-type','num-of-cylinders','engine-size','fuel-system','bore',\n",
    "                        'stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg']]\n",
    "df_imports_label = imports[imports.columns[-1]]\n",
    "df_imports_label = pd.to_numeric(df_imports_label)\n",
    "df_imports_data = cut_column(df_imports_data,3)\n",
    "val,tid = column_transform(df_imports_data,df_imports_label)\n",
    "counter = set()\n",
    "mu = opus_ir_pro(100,val,tid,25,'mean',adjust=0,pro=0,independent_pro=0)\n",
    "mu_a, mu_ai,mu_af = opus_ir_pro(100,val,tid,25,'mean',adjust=0,pro=1,independent_pro=1)\n",
    "mu_lcv, mu_lcvi, mu_lcvf = opus_ir_pro(100,val,tid,25,'mean',adjust=1,pro=1,independent_pro=1)\n",
    "impact = opus_ir_pro(100,val,tid,25,'impact',adjust=0,pro=0,independent_pro=0)\n",
    "impact_a, impact_ai,impact_af = opus_ir_pro(100,val,tid,25,'impact',adjust=0,pro=1,independent_pro=1)\n",
    "impact_lcv, impact_lcvi, impact_lcvf = opus_ir_pro(100,val,tid,25,'impact',adjust=1,pro=1,independent_pro=1)\n",
    "l = [mu,mu_a,mu_ai,mu_lcv,mu_lcvi,impact,impact_a,impact_ai,impact_lcv,impact_lcvi] \n",
    "print ('number of transactions' + ': ' + str(len(tid.keys())))\n",
    "print ('number of records' + ': ' + str(len(val)))\n",
    "for i in l:\n",
    "    print len(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with opus impact rule mining algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 49.3 ms per loop\n"
     ]
    }
   ],
   "source": [
    "imports = pd.read_csv('imports-85.data',header = -1)\n",
    "imports.columns = ['symboling','normalized-losses','make','fuel-type','aspiration','num-of-doors',\n",
    "                   'body-style','drive-wheels','engine-location','wheel-base','length','width','height',\n",
    "                   'curb-weight','engine-type','num-of-cylinders','engine-size','fuel-system','bore',\n",
    "                   'stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg','price']\n",
    "imports = imports[imports.price.apply(lambda x: x.isdigit())]\n",
    "df_imports_data = imports[['symboling','normalized-losses','make','fuel-type','aspiration','num-of-doors',\n",
    "                        'body-style','drive-wheels','engine-location','wheel-base','length','width','height',\n",
    "                        'curb-weight','engine-type','num-of-cylinders','engine-size','fuel-system','bore',\n",
    "                        'stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg']]\n",
    "df_imports_label = imports[imports.columns[-1]]\n",
    "df_imports_label = pd.to_numeric(df_imports_label)\n",
    "df_imports_data = cut_column(df_imports_data,3)\n",
    "df_imports_data.to_csv('df_imports_data_weka.csv',index = False)\n",
    "val,tid = column_transform(df_imports_data,df_imports_label)\n",
    "%timeit (opus_ir_pro(100,val,tid,13,'mean',adjust=0,pro=0,independent_pro=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transactions = df_imports_data.values.tolist()\n",
    "print (len(list(apriori(transactions,min_support = 0.1, min_confidence = 0.9))))\n",
    "%timeit ((list(apriori(transactions,min_support = 0.1, min_confidence = 0.9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:<br>\n",
    "With impact rule mining algorithm, the run time is less than one seconds but with apriori need excessive computing time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bank\n",
    "This database is created by Paulo Cortez and Sérgio Moro (2012). The originally use of this database is to use data mining for bank marketing, and the classification target is to predict if the client will subscribe a term deposit. In our experiment, we will discover interraltionship between quantitative attributes balance and other attributes. Totally 10 attributes are included in this dataset, with 2 quanntitative attributes and 8 qualitative attributes in 45211 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transactions: 34\n",
      "number of records: 45211\n",
      "100\n",
      "100\n",
      "100\n",
      "46\n",
      "43\n",
      "100\n",
      "33\n",
      "33\n",
      "29\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "def cut_column(df,num):\n",
    "    for i in df.columns:\n",
    "        if df[i].nunique()>num and  df[i].dtype != 'O':\n",
    "            df[i] = pd.qcut(df[i].values, num, retbins=True,duplicates= 'drop')[0]\n",
    "        df[i] = str(i) + ' ' + df[i].astype(str)\n",
    "    return df\n",
    "bank = pd.read_csv('bank.csv',header = 0)\n",
    "bank_data = bank[[u'age', u'job', u'marital', u'education', u'default',\n",
    "                  u'housing', u'loan', u'poutcome', u'y']]\n",
    "bank_label = bank['balance'] \n",
    "bank_data = cut_column(bank_data,3)\n",
    "val,tid = column_transform(bank_data,bank_label)\n",
    "mu = opus_ir_pro(100,val,tid,9,'mean',adjust=0,pro=0,independent_pro=0)\n",
    "mu_a, mu_ai,mu_af = opus_ir_pro(100,val,tid,9,'mean',adjust=0,pro=1,independent_pro=1)\n",
    "mu_lcv, mu_lcvi,mu_lf = opus_ir_pro(100,val,tid,9,'mean',adjust=1,pro=1,independent_pro=1)\n",
    "impact = opus_ir_pro(100,val,tid,9,'impact',adjust=0,pro=0,independent_pro=0)\n",
    "impact_a, impact_ai,impact_af = opus_ir_pro(100,val,tid,9,'impact',adjust=0,pro=1,independent_pro=1)\n",
    "impact_lcv, impact_lcvi,impact_lf = opus_ir_pro(100,val,tid,9,'impact',adjust=1,pro=1,independent_pro=1)\n",
    "l = [mu,mu_a,mu_ai,mu_lcv,mu_lcvi,impact,impact_a,impact_ai,impact_lcv,impact_lcvi] \n",
    "print ('number of transactions' + ': ' + str(len(tid.keys())))\n",
    "print ('number of records' + ': ' + str(len(val)))\n",
    "for i in l:\n",
    "    print len(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with opus impact rule mining algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 3min 46s per loop\n"
     ]
    }
   ],
   "source": [
    "def cut_column(df,num):\n",
    "    for i in df.columns:\n",
    "        if df[i].nunique()>num and  df[i].dtype != 'O':\n",
    "            df[i] = pd.qcut(df[i].values, num, retbins=True,duplicates= 'drop')[0]\n",
    "        df[i] = str(i) + ' ' + df[i].astype(str)\n",
    "    return df\n",
    "bank = pd.read_csv('bank.csv',header = 0)\n",
    "bank_data = bank[[u'age', u'job', u'marital', u'education', u'default',\n",
    "                  u'housing', u'loan', u'poutcome', u'y']]\n",
    "bank_label = bank['balance'] \n",
    "bank_data = cut_column(bank_data,3)\n",
    "bank_data.to_csv('bank_data_weka.csv',index = False)\n",
    "val,tid = column_transform(bank_data,bank_label)\n",
    "%timeit (opus_ir_pro(100,val,tid,9,'mean',adjust=0,pro=0,independent_pro=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transactions = df_imports_data.values.tolist()\n",
    "print (len(list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))\n",
    "%timeit ((list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:<br>\n",
    "With impact rule mining algorithm, the run time is 226 seconds but with apriori need excessive computing time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transactions: 18\n",
      "number of records: 209\n",
      "100\n",
      "13\n",
      "7\n",
      "6\n",
      "6\n",
      "100\n",
      "8\n",
      "4\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "cpu = pd.read_csv('cpu_performance_c.data',header = -1)\n",
    "cpu.columns = [['vendor','model','MYCT','MMIN','MMAX','CACH','CHMIN','CHMAX',\n",
    "               'RPR','ERP']]\n",
    "cpu_data = cpu[['MYCT','MMIN','MMAX','CACH','CHMIN','CHMAX']]\n",
    "cpu_label = cpu[cpu.columns[-2]]\n",
    "cpu_data = cut_column(cpu_data,3)\n",
    "val,tid = column_transform(cpu_data,cpu_label)\n",
    "mu = opus_ir_pro(100,val,tid,6,'mean',adjust=0,pro=0,independent_pro=0)\n",
    "mu_a, mu_ai,mu_af = opus_ir_pro(100,val,tid,6,'mean',adjust=0,pro=1,independent_pro=1)\n",
    "mu_lcv, mu_lcvi, mu_lcvf = opus_ir_pro(100,val,tid,6,'mean',adjust=1,pro=1,independent_pro=1)\n",
    "impact = opus_ir_pro(100,val,tid,6,'impact',adjust=0,pro=0,independent_pro=0)\n",
    "impact_a, impact_ai,impact_af = opus_ir_pro(100,val,tid,6,'impact',adjust=0,pro=1,independent_pro=1)\n",
    "impact_lcv, impact_lcvi, impact_lcvf = opus_ir_pro(100,val,tid,6,'impact',adjust=1,pro=1,independent_pro=1)\n",
    "l = [mu,mu_a,mu_ai,mu_lcv,mu_lcvi,impact,impact_a,impact_ai,impact_lcv,impact_lcvi] \n",
    "print ('number of transactions' + ': ' + str(len(tid.keys())))\n",
    "print ('number of records' + ': ' + str(len(val)))\n",
    "for i in l:\n",
    "    print len(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with opus impact rule mining algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 19.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "cpu = pd.read_csv('cpu_performance_c.data',header = -1)\n",
    "cpu.columns = [['vendor','model','MYCT','MMIN','MMAX','CACH','CHMIN','CHMAX',\n",
    "               'RPR','ERP']]\n",
    "cpu_data = cpu[['MYCT','MMIN','MMAX','CACH','CHMIN','CHMAX']]\n",
    "cpu_label = cpu[cpu.columns[-2]]\n",
    "cpu_data = cut_column(cpu_data,3)\n",
    "cpu_data.to_csv('cpu_data_weka.csv',index = False)\n",
    "val,tid = column_transform(cpu_data,cpu_label)\n",
    "%timeit (opus_ir_pro(100,val,tid,6,'mean',adjust=0,pro=0,independent_pro=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "10 loops, best of 3: 37.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "transactions = cpu_data.values.tolist()\n",
    "print (len(list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))\n",
    "%timeit ((list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Concrete\n",
    "This dataset is created by Prof. I-Cheng Yeh. There are 9 relative attribute in the data set, and the originally use of this data set is to predict the concrete compressive strength. In our find, we will try to find the interationship between attribute concrete compressive strength and other attributes. The dataset contains 8 quantitative attributes and 1 qualitative attribute with 1030 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut_column(df,num):\n",
    "    for i in df.columns:\n",
    "        if df[i].nunique()>num and  df[i].dtype != 'O':\n",
    "            df[i] = pd.qcut(df[i].values, num, retbins=True,duplicates= 'drop')[0]\n",
    "        df[i] = str(i) + ' ' + df[i].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transactions: 20\n",
      "number of records: 1030\n",
      "100\n",
      "64\n",
      "52\n",
      "24\n",
      "19\n",
      "100\n",
      "14\n",
      "8\n",
      "12\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "concrete = pd.read_excel('Concrete_Data_c.xls',header = -1)\n",
    "concrete.columns = [u'Cement', u'Blast Furnace Slag', u'Fly Ash',u'Water',u'Superplasticizer',\n",
    "                    u'Coarse Aggregate',u'Fine Aggregate', u'Age',u'Concrete compressive strength']\n",
    "concrete_data = concrete[[u'Cement', u'Blast Furnace Slag', u'Fly Ash',u'Water',u'Superplasticizer',\n",
    "                          u'Coarse Aggregate',u'Fine Aggregate', u'Age']]\n",
    "concrete_label = concrete[concrete.columns[-1]]\n",
    "concrete_data = cut_column(concrete_data,3)\n",
    "val,tid = column_transform(concrete_data,concrete_label)\n",
    "mu = opus_ir_pro(100,val,tid,8,'mean',adjust=0,pro=0,independent_pro=0)\n",
    "mu_a, mu_ai,mu_af = opus_ir_pro(100,val,tid,8,'mean',adjust=0,pro=1,independent_pro=1)\n",
    "mu_lcv, mu_lcvi, mu_lcvf = opus_ir_pro(100,val,tid,8,'mean',adjust=1,pro=1,independent_pro=1)\n",
    "impact = opus_ir_pro(100,val,tid,8,'impact',adjust=0,pro=0,independent_pro=0)\n",
    "impact_a, impact_ai,impact_af = opus_ir_pro(100,val,tid,8,'impact',adjust=0,pro=1,independent_pro=1)\n",
    "impact_lcv, impact_lcvi, impact_lcvf = opus_ir_pro(100,val,tid,8,'impact',adjust=1,pro=1,independent_pro=1)\n",
    "l = [mu,mu_a,mu_ai,mu_lcv,mu_lcvi,impact,impact_a,impact_ai,impact_lcv,impact_lcvi] \n",
    "print ('number of transactions' + ': ' + str(len(tid.keys())))\n",
    "print ('number of records' + ': ' + str(len(val)))\n",
    "for i in l:\n",
    "    print len(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with opus impact rule mining algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 264 ms per loop\n"
     ]
    }
   ],
   "source": [
    "concrete = pd.read_excel('Concrete_Data_c.xls',header = -1)\n",
    "concrete.columns = [u'Cement', u'Blast Furnace Slag', u'Fly Ash',u'Water',u'Superplasticizer',\n",
    "                    u'Coarse Aggregate',u'Fine Aggregate', u'Age',u'Concrete compressive strength']\n",
    "concrete_data = concrete[[u'Cement', u'Blast Furnace Slag', u'Fly Ash',u'Water',u'Superplasticizer',\n",
    "                          u'Coarse Aggregate',u'Fine Aggregate', u'Age']]\n",
    "concrete_label = concrete[concrete.columns[-1]]\n",
    "concrete_data = cut_column(concrete_data,3)\n",
    "concrete_data.to_csv('concrete_data_weka.csv',index = False)\n",
    "val,tid = column_transform(concrete_data,concrete_label)\n",
    "%timeit (opus_ir_pro(100,val,tid,8,'mean',adjust=0,pro=0,independent_pro=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302\n",
      "1 loop, best of 3: 291 ms per loop\n"
     ]
    }
   ],
   "source": [
    "transactions = concrete_data.values.tolist()\n",
    "print (len(list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))\n",
    "%timeit ((list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust significant test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target value of intersect set and parent set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new =  ['Fine Aggregate (593.999, 754.3]', 'Blast Furnace Slag (-0.001, 116.0]']\n",
    "inter = set.intersection(*map(set,[tid[i] for i in new]))\n",
    "val1 = [val[i] for i in inter]\n",
    "val2 = [val[i] for i in tid['Fine Aggregate (593.999, 754.3]']]\n",
    "val3 = [val[i] for i in tid['Blast Furnace Slag (-0.001, 116.0]']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.61326969512568"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.524487540954631"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.863940637021763"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T test between intersect and parent rule 'Blast Furnace Slag (-0.001, 116.0]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6655567996842004e-07"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t , p_val = ttest_ind(val3, val1, equal_var=True)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T test between intersect and parent rule 'Fine Aggregate (593.999, 754.3]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027085168958895688"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t , p_val = ttest_ind(val2, val1, equal_var=True)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:<br>\n",
    "For rule 'Fine Aggregate (593.999, 754.3)', 'Blast Furnace Slag (-0.001, 116.0), this rule is non redundant as the target mean of this rule is 41.61326969512568 while the figure of parent rule 'Fine Aggregate (593.999, 754.3)' and , 'Blast Furnace Slag (-0.001, 116.0) are 38.524487540954631 and 34.863940637021763. Meanwhile, this rule is productive when we set significant level to 0.05 and the p-value of t test against the two parent rules are 3.6655567996842004e-07 and 0.027085168958895688. By applying adjust significant level, we are able to ensure that the false positive rate in current level will not be higher than 0.05. Thus, in this problem, as the p-value between target value of 'Fine Aggregate (593.999, 754.3)', 'Blast Furnace Slag (-0.001, 116.0) and 'Fine Aggregate (593.999, 754.3)' is higher than adjust significant level, this rule is not productive.<br>\n",
    "Beside the statistical analyse, we can also explain why this rule is not interesting by using domain expertise. For concrete, when Blast Furnace Slag is low, the strength of concrete is low. While 'Blast Furnace Slag (-0.001, 116.0) is the lowest range of Blast Furnace Slag, add this item to 'Fine Aggregate (593.999, 754.3)' does not make sense to improve the strength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie\n",
    "This dataset is collected from movies data sets on Web, Twitter, YouTube and IMDB. The data set contains 217 movies with 12 relative attributes between 2014 and 2015. In our experiment, we are going to discover the interrelationship between profit margin and \n",
    "other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut_column(df,num):\n",
    "    for i in df.columns:\n",
    "        if df[i].nunique()>num and  df[i].dtype != 'O':\n",
    "            df[i] = pd.qcut(df[i].values, num, retbins=True,duplicates= 'drop')[0]\n",
    "        df[i] = str(i) + ' ' + df[i].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transactions: 32\n",
      "number of records: 229\n",
      "100\n",
      "100\n",
      "100\n",
      "72\n",
      "72\n",
      "100\n",
      "82\n",
      "65\n",
      "52\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "movie = pd.read_excel('movie_c.xlsx',header = -1)\n",
    "movie = movie[-movie['Budget'].isnull()]\n",
    "movie = movie.drop(movie.index[[-1]])\n",
    "movie_data = movie[[u'Year', u'Ratings', u'Genre',\n",
    "                    u'Screens', u'Sequel', u'Sentiment', u'Views', u'Likes', u'Dislikes',\n",
    "                    u'Comments', u'Aggregate Followers']]\n",
    "movie_label = (movie[u'Gross'] - movie[u'Budget'])/movie[u'Budget']\n",
    "movie_data = cut_column(movie_data,3)\n",
    "val,tid = column_transform(movie_data,movie_label)\n",
    "mu = opus_ir_pro(100,val,tid,11,'mean',adjust=0,pro=0,independent_pro=0)\n",
    "mu_a, mu_ai,mu_af = opus_ir_pro(100,val,tid,11,'mean',adjust=0,pro=1,independent_pro=1)\n",
    "mu_lcv, mu_lcvi, mu_lcvf = opus_ir_pro(100,val,tid,11,'mean',adjust=1,pro=1,independent_pro=1)\n",
    "impact = opus_ir_pro(100,val,tid,11,'impact',adjust=0,pro=0,independent_pro=0)\n",
    "impact_a, impact_ai,impact_af = opus_ir_pro(100,val,tid,11,'impact',adjust=0,pro=1,independent_pro=1)\n",
    "impact_lcv, impact_lcvi, impact_lcvf = opus_ir_pro(100,val,tid,11,'impact',adjust=1,pro=1,independent_pro=1)\n",
    "l = [mu,mu_a,mu_ai,mu_lcv,mu_lcvi,impact,impact_a,impact_ai,impact_lcv,impact_lcvi]\n",
    "print ('number of transactions' + ': ' + str(len(tid.keys())))\n",
    "print ('number of records' + ': ' + str(len(val)))\n",
    "for i in l:\n",
    "    print len(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with opus impact rule mining algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 112 ms per loop\n"
     ]
    }
   ],
   "source": [
    "movie = pd.read_excel('movie_c.xlsx',header = -1)\n",
    "movie = movie[-movie['Budget'].isnull()]\n",
    "movie = movie.drop(movie.index[[-1]])\n",
    "movie_data = movie[[u'Year', u'Ratings', u'Genre',\n",
    "                    u'Screens', u'Sequel', u'Sentiment', u'Views', u'Likes', u'Dislikes',\n",
    "                    u'Comments', u'Aggregate Followers']]\n",
    "movie_label = (movie[u'Gross'] - movie[u'Budget'])/movie[u'Budget']\n",
    "movie_data = cut_column(movie_data,3)\n",
    "movie_data.to_csv('movie_data_weka.csv',index = False)\n",
    "val,tid = column_transform(movie_data,movie_label)\n",
    "%timeit (opus_ir_pro(100,val,tid,12,'mean',adjust=0,pro=0,independent_pro=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2877\n",
      "1 loop, best of 3: 13.4 s per loop\n"
     ]
    }
   ],
   "source": [
    "transactions = movie_data.values.tolist()\n",
    "print (len(list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))\n",
    "%timeit ((list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(19.826017951777104,\n",
       "  'Year 2015',\n",
       "  'Dislikes (-0.001, 155.0]',\n",
       "  'Ratings (6.8, 8.7]'),\n",
       " (20.182948966994733,\n",
       "  'Aggregate Followers (276457.667, 2376333.333]',\n",
       "  'Year 2015',\n",
       "  'Sentiment (0.0, 3.0]',\n",
       "  'Dislikes (-0.001, 155.0]'),\n",
       " (21.385755984538594,\n",
       "  'Views (697.999, 1142295.0]',\n",
       "  'Year 2015',\n",
       "  'Sentiment (0.0, 3.0]',\n",
       "  'Ratings (6.8, 8.7]')}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([i[:-1] for i in impact_af if 'Year 2015' in i and  ('Dislikes (-0.001, 155.0]' in i or  'Views (697.999, 1142295.0]' in i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2567366408017537"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new =  ['Year 2015']\n",
    "inter = set.intersection(*map(set,[tid[i] for i in new]))\n",
    "val1 = [val[i] for i in inter]\n",
    "np.mean(val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94526441306376707"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new =  ['Year 2015',\n",
    "  'Dislikes (-0.001, 155.0]',\n",
    "  'Ratings (6.8, 8.7]']\n",
    "inter = set.intersection(*map(set,[tid[i] for i in new]))\n",
    "val2 = [val[i] for i in inter]\n",
    "np.mean([i for i in val1 if i not in val2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1537886743973702"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Summary:<br>\n",
    "Independent productivity is important to filter uninteresting parent impact rules. We will examine independent productivity for productive rules. In the experiment against dataset movie, we discovered 88 productive rules with configuration ‘OPUS_impact_pro’-search by impact and perform t test. One of the resulting rule is: (6.8975137490936964, 'Year 2015'). Before we examine independent productivity, we would verify this rule could fulfil the measurement of non-redundancy and productivity.  The target impact value of impact rule 'Year 2015' is in the top 100 list. At the mean time, as this rule formed by one element, so there are no parent rule. Thus, this rule is productive and non-redundant. However, the fact hidden in this pattern is not meaningful. Independent productivity algorithm proves this hypothesis by filter this rule. In the resulting productive rules, we found 3 supersets for this itemset. Take one of the superset 'Year 2015', 'Dislikes (-0.001, 155.0)', 'Ratings (6.8, 8.7)' as example, when we exclude the records with itemsets 'Year 2015', 'Dislikes (-0.001, 155.0)', 'Ratings (6.8, 8.7)' for the itemset 'Year 2015', 5 records are removed but the mean target value dropped from 1.2567366408017537 to 0.94526441306376707. While the global mean is 1.1537886743973702, the impact turned to negative. Thus rule 'Year 2015' is not independent productive.<br>\n",
    "We could explain why this impact rule is uninteresting by using domain expertise beside the statistical analysis. ‘A movie produced in 2015’ does not make too much sense that it can earn more money. However, we have more knowledge about the film by appending more items to the rule, such as ‘the ratings of this movie is high’ and ‘the dislike of this movie is low’. With principle of independent productivity, we are able to discovery rules with sufficient knowledge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy\n",
    "The dataset is originally created by Angeliki Xifara and processed by Athanasios Tsanas. The past use of this dataset is to implement energy efficiency analysis with 12 different building and to predict the attribute heating load. In our experiment, we are going to find interrelationship between attribute heating load and other attributes, There are 8 features in the dataset, 4 qualitative and 4 quantitative attributes with 768 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transactions: 22\n",
      "number of records: 768\n",
      "100\n",
      "34\n",
      "29\n",
      "33\n",
      "29\n",
      "100\n",
      "14\n",
      "11\n",
      "14\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "energy = pd.read_excel('ENB2012_data_c.xlsx',header = -1)\n",
    "energy.columns = ['Relative Compactness','Surface Area','Wall Area','Roof Area','Overall Height',\n",
    "                  'Orientation','Glazing Area','Glazing Area Distribution','Heating Load','Cooling Load']\n",
    "energy_data = energy[['Relative Compactness','Surface Area','Wall Area','Roof Area','Overall Height',\n",
    "                      'Orientation','Glazing Area','Glazing Area Distribution']]\n",
    "energy_label = energy['Heating Load']\n",
    "energy_data = cut_column(energy_data,3)\n",
    "val,tid = column_transform(energy_data,energy_label)\n",
    "mu = opus_ir_pro(100,val,tid,12,'mean',adjust=0,pro=0,independent_pro=0)\n",
    "mu_a, mu_ai,mu_af = opus_ir_pro(100,val,tid,12,'mean',adjust=0,pro=1,independent_pro=1)\n",
    "mu_lcv, mu_lcvi, mu_lcvf = opus_ir_pro(100,val,tid,12,'mean',adjust=1,pro=1,independent_pro=1)\n",
    "impact = opus_ir_pro(100,val,tid,12,'impact',adjust=0,pro=0,independent_pro=0)\n",
    "impact_a, impact_ai,impact_af = opus_ir_pro(100,val,tid,12,'impact',adjust=0,pro=1,independent_pro=1)\n",
    "impact_lcv, impact_lcvi, impact_lcvf = opus_ir_pro(100,val,tid,12,'impact',adjust=1,pro=1,independent_pro=1)\n",
    "l = [mu,mu_a,mu_ai,mu_lcv,mu_lcvi,impact,impact_a,impact_ai,impact_lcv,impact_lcvi] \n",
    "print ('number of transactions' + ': ' + str(len(tid.keys())))\n",
    "print ('number of records' + ': ' + str(len(val)))\n",
    "for i in l:\n",
    "    print len(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with opus impact rule mining algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jason/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 191 ms per loop\n"
     ]
    }
   ],
   "source": [
    "energy = pd.read_excel('ENB2012_data_c.xlsx',header = -1)\n",
    "energy.columns = ['Relative Compactness','Surface Area','Wall Area','Roof Area','Overall Height',\n",
    "                  'Orientation','Glazing Area','Glazing Area Distribution','Heating Load','Cooling Load']\n",
    "energy_data = energy[['Relative Compactness','Surface Area','Wall Area','Roof Area','Overall Height',\n",
    "                      'Orientation','Glazing Area','Glazing Area Distribution']]\n",
    "energy_label = energy['Heating Load']\n",
    "energy_data = cut_column(energy_data,3)\n",
    "energy_data.to_csv('energy_data_weka.csv',index = False)\n",
    "val,tid = column_transform(energy_data,energy_label)\n",
    "%timeit (opus_ir_pro(100,val,tid,12,'mean',adjust=0,pro=0,independent_pro=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time with apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861\n",
      "1 loop, best of 3: 421 ms per loop\n"
     ]
    }
   ],
   "source": [
    "transactions = energy_data.values.tolist()\n",
    "print (len(list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))\n",
    "%timeit ((list(apriori(transactions,min_support = 0.05, min_confidence = 0.9))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
